---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/app-template-4.1.2/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app home-assistant
  namespace: *app
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 4.1.2
      sourceRef:
        name: bjw-s
        kind: HelmRepository
        namespace: flux-system
  values:
    controllers:
      app:
        type: deployment
        replicas: 1
        pod:
          hostname: "home-assistant"
          labels:
            ingress.home.arpa/nginx-internal: allow
            ingress.home.arpa/world: allow
            egress.home.arpa/iot: allow
            egress.home.arpa/esp: allow
            egress.home.arpa/appletv: allow
            egress.home.arpa/r2: allow
            egress.home.arpa/pypi: allow # entrypoint does a `uv pip install uv` in the venv
            egress.home.arpa/github: allow # TODO: try to harden this eventually, maybe HACS as ImageVolume?
            authentik.home.arpa/https: allow
            db.home.arpa/mqtt: allow
            prom.home.arpa/kps: allow
            dns.home.arpa/l7: "true"
          annotations:
            # generate reproducible "locally assigned" (aka non-vendor-assigned) MAC address from a FQDN (e.g. for Home Assistant Multus)
            # `echo "$FQDN" | md5sum | sed 's/^\(..\)\(..\)\(..\)\(..\)\(..\).*$/02:\1:\2:\3:\4:\5/'`
            # source: https://serverfault.com/questions/299556/how-to-generate-a-random-mac-address-from-the-linux-command-line/299563#299563
            k8s.v1.cni.cncf.io/networks: |
              [{
                "name":"iot",
                "namespace": "multus",
                "ips": ["${APP_IP_HOME_ASSISTANT_IOT}"],
                "mac": "${APP_MAC_HOME_ASSISTANT_IOT}",
                "gateway": "${IP_ROUTER_VLAN_IOT}"
              }]
          resources:
            requests:
              cpu: 30m
            limits:
              cpu: 1
              memory: 1Gi
        containers:
          app:
            image:
              repository: ghcr.io/home-operations/home-assistant
              tag: 2025.11.3@sha256:8cdb8a2ae0bd6d96b4c0bb1cd529cf97a7634a40ca8ac3b6ebd824a5583a7281
            env:
              TZ: "${CONFIG_TZ}"
            #envFrom:
            #  - secretRef:
            #      name: "home-assistant-secrets"
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: ["ALL"]
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
    service:
      app:
        primary: true
        controller: app
        forceRename: *app
        ports:
          http:
            port: 8123
            protocol: TCP
            appProtocol: http
            primary: true
      expose:
        primary: false
        controller: app
        type: LoadBalancer
        annotations:
          "io.cilium/lb-ipam-ips": "${APP_IP_HOME_ASSISTANT:=127.0.0.1}"
        ports:
          homekit:
            port: 21061
            protocol: TCP
            primary: false
          homekit-denon:
            port: 21062
            protocol: TCP
            primary: false
          homekit-sensors:
            port: 21063
            protocol: TCP
            primary: false
          homekit-4:
            port: 21064
            protocol: TCP
            primary: false
          homekit-5:
            port: 21065
            protocol: TCP
            primary: false
          homekit-6:
            port: 21066
            protocol: TCP
            primary: false
    ingress:
      main:
        className: "nginx-internal"
        hosts:
          - host: &host "${APP_DNS_HOME_ASSISTANT:=home-assistant}"
            paths: &paths
              - path: /
                pathType: Prefix
                service:
                  identifier: app
                  port: http
        tls: &tls
          - hosts: [*host]
    persistence:
      config:
        existingClaim: "home-assistant-data"
        advancedMounts:
          app:
            app: &pvc
              - subPath: "config"
                path: "/config"
            litestream: *pvc
            01-litestream-restore: *pvc
      tmp:
        type: emptyDir
        medium: Memory
        sizeLimit: 50Mi
        globalMounts:
          - subPath: "tmp"
            path: "/tmp"
            readOnly: false
          - subPath: logs
            path: /config/logs
            readOnly: false
      litestream:
        type: secret
        name: "litestream-secrets"
        advancedMounts:
          app:
            litestream: &lsmnt
              - subPath: "litestream.yml"
                path: "/etc/litestream.yml"
                readOnly: true
            01-litestream-restore: *lsmnt
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      # hostUsers: false
      runtimeClassName: kata
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534 # image needs this for uv workaround perms
        runAsGroup: &gid 65533
        fsGroup: *gid
        fsGroupChangePolicy: "Always"
        seccompProfile: { type: "RuntimeDefault" }
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "fuckoff.home.arpa/home-assistant"
                    operator: "DoesNotExist"
      hostAliases:
        - ip: "${APP_IP_AUTHENTIK:=127.0.0.1}"
          hostnames: ["${APP_DNS_AUTHENTIK:=authentik}"]
      dnsConfig:
        options:
          - name: ndots
            value: "1"
    serviceMonitor:
      app:
        service:
          identifier: app
        endpoints:
          - port: http
            scheme: http
            path: /api/prometheus
