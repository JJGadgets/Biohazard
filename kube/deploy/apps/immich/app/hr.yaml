---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/app-template-4.1.2/charts/other/app-template/schemas/helmrelease-helm-v2beta2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app immich
  namespace: *app
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 4.1.2
      sourceRef:
        name: bjw-s
        kind: HelmRepository
        namespace: flux-system
  values:
    controllers:
      app:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        pod:
          labels:
            ingress.home.arpa/nginx-internal: allow
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
            authentik.home.arpa/https: allow
        containers:
          main:
            image: &img
              repository: ghcr.io/immich-app/immich-server
              tag: v1.137.3@sha256:e517f806457057d44695152a0af2dfa094225a7d85eb37f518925e68864c658d
            # command: &cmd ["tini", "--", "node", "/usr/src/app/server/dist/main"]
            env: &env
              TZ: "${CONFIG_TZ}"
              NODE_ENV: production
              LOG_LEVEL: verbose
              IMMICH_TRUSTED_PROXIES: "${IP_POD_CIDR_V4:=127.0.0.1/32}"
              IMMICH_WORKERS_INCLUDE: "api"
              IMMICH_MEDIA_LOCATION: &pvc /data
              IMMICH_TELEMETRY_INCLUDE: "all"
              IMMICH_API_METRICS_PORT: &metrics-api 8081
              IMMICH_MICROSERVICES_METRICS_PORT: &metrics-ms 8081
              IMMICH_SERVER_URL: http://immich.immich.svc.cluster.local:3001
              REDIS_HOSTNAME: immich-redis.immich.svc.cluster.local
              REDIS_PORT: "6379"
              DB_VECTOR_EXTENSION: pgvector # I couldn't really care less for worser machine learning, over half my library is screenshots
              IMMICH_MACHINE_LEARNING_URL: http://immich-ml.immich.svc.cluster.local:3003
              MACHINE_LEARNING_HTTP_KEEPALIVE_TIMEOUT_S: "0" # avoid keep-alive to better load balance requests across replicas
              MACHINE_LEARNING_MODEL_TTL: "0" # keep models loaded, for predictable resource requests
              # default models as of v1.112.1
              MACHINE_LEARNING_PRELOAD__CLIP: ViT-B-32__openai
              MACHINE_LEARNING_PRELOAD__FACIAL_RECOGNITION: buffalo_l
              DB_URL:
                valueFrom:
                  secretKeyRef:
                    name: pg-home-pguser-immich-fixed
                    key: pgbouncer-uri-sslmode
              CPU_CORES:
                resourceFieldRef:
                  resource: limits.cpu
            envFrom: &ef
              - secretRef:
                  name: immich-secrets
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: ["ALL"]
            resources:
              requests:
                cpu: 10m
                memory: "128Mi"
              limits:
                cpu: "1"
                memory: "2Gi"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      microservices:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
          securityContext:
            supplementalGroups: [44, 104, 109, 128, 226] # GPU
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/instance: *app
                  app.kubernetes.io/controller: microservices
        containers:
          main:
            image: *img
            env:
              <<: *env
              IMMICH_WORKERS_INCLUDE: "microservices"
            envFrom: *ef
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "300Mi"
              limits:
                cpu: "1"
                memory: "2Gi"
                gpu.intel.com/i915: "1"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      ml:
        type: deployment
        replicas: 3
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
          securityContext:
            supplementalGroups: [44, 104, 109, 128, 226] # GPU
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/instance: *app
                  app.kubernetes.io/controller: ml
        containers:
          main:
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v1.137.1-openvino@sha256:8e3c49ff6fb9ece642e4b29714229b9229cfc5d7cbf7e9a535f188c439fb2b48
            env:
              <<: *env
              MACHINE_LEARNING_REQUEST_THREADS:
                resourceFieldRef:
                  resource: limits.cpu
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "1Gi"
              limits:
                cpu: "1"
                memory: "6Gi"
                gpu.intel.com/i915: "1"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      ml-model-pull-clip: &ml-model-pull
        type: cronjob
        cronjob:
          schedule: "@yearly"
          concurrencyPolicy: "Replace"
        pod:
          labels:
            egress.home.arpa/internet: allow
        containers:
          main: &ml-model-pull-ct
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v1.137.1@sha256:591a7aef2a9ae087beb5aa24901ecffd441c8dc85db2a5addc6e08f4dbcddee3
            command: ["huggingface-cli", "download", "--exclude", ".git", "--local-dir"] # Immich ML image installs huggingface-cli
            args: ["/cache/clip/ViT-B-32__openai", "immich-app/ViT-B-32__openai"]
            workingDir: &mlhome "/cache"
            env:
              HOME: *mlhome
              HF_HOME: *mlhome
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
              limits:
                cpu: "1"
                memory: "2Gi"
      ml-model-pull-facial:
        <<: *ml-model-pull
        cronjob:
          schedule: "@yearly"
          concurrencyPolicy: "Replace"
        containers:
          main:
            <<: *ml-model-pull-ct
            args: ["/cache/facial-recognition/buffalo_l", "immich-app/buffalo_l"]
      redis:
        type: deployment
        replicas: 1
        containers:
          redis:
            image:
              repository: "public.ecr.aws/docker/library/redis"
              tag: "8.0.3@sha256:f957ce918b51f3ac10414244bedd0043c47db44a819f98b9902af1bd9d0afcea"
            command: ["redis-server", "--save", "300 1", "--appendonly", "yes"] # save and appendonly options forcibly disable RDB and AOF persistence entirely
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "32Mi"
              limits:
                cpu: "1"
                memory: "512Mi"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
    service:
      app:
        controller: app
        primary: true
        forceRename: *app
        ports:
          http:
            port: 2283
            primary: true
          metrics:
            port: *metrics-api
      microservices:
        controller: microservices
        ports:
          metrics:
            port: *metrics-ms
      ml:
        controller: ml
        ports:
          http:
            port: 3003
      redis:
        controller: redis
        ports:
          http:
            port: 6379
    ingress:
      main:
        className: nginx-internal
        hosts:
          - host: &host "${APP_DNS_IMMICH:=immich}"
            paths: &paths
              - path: /
                pathType: Prefix
                service:
                  identifier: app
                  port: http
        tls:
          - hosts: [*host]
    persistence:
      data:
        existingClaim: immich-data
        advancedMounts:
          app: &mount
            main:
              - subPath: data
                path: *pvc
          microservices: *mount
          redis:
            redis:
              - subPath: redis
                path: /data
      misc:
        existingClaim: immich-misc
        advancedMounts:
          app: &misc
            main:
              - subPath: encodedvideo
                path: /data/encoded-video
              - subPath: thumbs
                path: /data/thumbs
          microservices: *misc
          ml: &mlpvc # buffalo needs to write to model file to add batch axis
            main:
              - subPath: ml-models-cache
                path: /cache
              - subPath: matplotlib-config
                path: /.config/matplotlib
              - subPath: matplotlib-cache
                path: /.cache/matplotlib
          ml-model-pull-facial: *mlpvc
          ml-model-pull-clip: *mlpvc
      tmp:
        type: emptyDir
        medium: Memory
        sizeLimit: 16Mi
        globalMounts:
          - subPath: tmp
            path: /tmp
          - subPath: geocode
            path: /usr/src/app/.reverse-geocoding-dump
          - subPath: geoname
            path: /usr/src/app/node_modules/local-reverse-geocoder/geonames_dump
          - subPath: transformers
            path: /usr/src/app/.transformers_cache
      pg-ca:
        type: secret
        name: pg-home-ca
        defaultMode: 0400
        globalMounts:
          - subPath: ca.crt
            path: /secrets/pg/ca.crt
    defaultPodOptionsStrategy: merge
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      hostAliases:
        - ip: "${APP_IP_AUTHENTIK:=127.0.0.1}"
          hostnames: ["${APP_DNS_AUTHENTIK:=authentik}"]
      securityContext:
        runAsNonRoot: true
        runAsUser: &uid ${APP_UID_IMMICH:=1000}
        runAsGroup: *uid
        fsGroup: *uid
        fsGroupChangePolicy: Always
        seccompProfile: { type: "RuntimeDefault" }
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: fuckoff.home.arpa/immich
                    operator: DoesNotExist
    networkpolicies:
      immich:
        podSelector: &sel
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values: [immich]
            - key: app.kubernetes.io/instance
              operator: NotIn
              values: [ml-model-pull]
        policyTypes: [Ingress, Egress]
        rules:
          ingress:
            - from: [{podSelector: *sel}]
          egress:
            - to: [{podSelector: *sel}]
    serviceMonitor:
      immich:
        service:
          identifier: app
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
      microservices:
        service:
          identifier: microservices
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
