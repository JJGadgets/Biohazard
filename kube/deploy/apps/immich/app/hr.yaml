---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/app-template-4.6.2/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app immich
  namespace: *app
spec:
  interval: 5m
  chartRef:
    kind: OCIRepository
    name: app-template
    namespace: *app
  values:
    controllers:
      app:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        pod:
          labels:
            ingress.home.arpa/envoy-internal: allow
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
            authentik.home.arpa/oidc: allow
        containers:
          app:
            image: &img
              repository: ghcr.io/immich-app/immich-server
              tag: v2.4.1@sha256:e6a6298e67ae077808fdb7d8d5565955f60b0708191576143fc02d30ab1389d1
            # command: &cmd ["tini", "--", "node", "/usr/src/app/server/dist/main"]
            env: &env
              TZ: "${CONFIG_TZ}"
              NODE_ENV: production
              LOG_LEVEL: verbose
              IMMICH_PORT: &http 8080
              IMMICH_TRUSTED_PROXIES: "${IP_POD_CIDR_V4:=127.0.0.1/32}"
              IMMICH_WORKERS_INCLUDE: "api"
              IMMICH_MEDIA_LOCATION: &pvc /data
              IMMICH_TELEMETRY_INCLUDE: "all"
              IMMICH_API_METRICS_PORT: &metrics-api 8081
              IMMICH_MICROSERVICES_METRICS_PORT: &metrics-ms 8081
              IMMICH_SERVER_URL: http://immich.immich.svc.cluster.local
              REDIS_HOSTNAME: immich-redis.immich.svc.cluster.local
              REDIS_PORT: "6379"
              DB_VECTOR_EXTENSION: pgvector # I couldn't really care less for worser machine learning, over half my library is screenshots
              IMMICH_MACHINE_LEARNING_URL: http://immich-ml.immich.svc.cluster.local
              MACHINE_LEARNING_HTTP_KEEPALIVE_TIMEOUT_S: "0" # avoid keep-alive to better load balance requests across replicas
              MACHINE_LEARNING_MODEL_TTL: "0" # keep models loaded, for predictable resource requests
              # default models as of v1.112.1
              MACHINE_LEARNING_PRELOAD__CLIP: ViT-B-32__openai
              MACHINE_LEARNING_PRELOAD__FACIAL_RECOGNITION: buffalo_l
              DB_URL:
                valueFrom:
                  secretKeyRef:
                    name: pg-home-pguser-immich-fixed
                    key: pgbouncer-uri-sslmode
              CPU_CORES:
                resourceFieldRef:
                  resource: limits.cpu
            envFrom: &ef
              - secretRef:
                  name: immich-secrets
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: ["ALL"]
            resources:
              requests:
                cpu: 10m
                memory: "128Mi"
              limits:
                cpu: "1"
                memory: "2Gi"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      microservices:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
          securityContext:
            supplementalGroups: [44] # GPU
        containers:
          app:
            image: *img
            env:
              <<: *env
              IMMICH_WORKERS_INCLUDE: "microservices"
            envFrom: *ef
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "300Mi"
              limits:
                cpu: "1"
                memory: "2Gi"
                gpu.intel.com/i915: "1"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      ml:
        type: deployment
        replicas: 3
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
          runtimeClassName: ""
          hostUsers: false
          securityContext:
            supplementalGroups: [44] # GPU
        containers:
          app:
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v2.4.1@sha256:b3deefd1826f113824e9d7bc30d905e7f823535887d03f869330946b6db3b44a
            env:
              <<: *env
              IMMICH_PORT: &ml-port 8080
              MACHINE_LEARNING_REQUEST_THREADS:
                resourceFieldRef:
                  resource: limits.cpu
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "1Gi"
              limits:
                cpu: "1"
                memory: "6Gi"
                gpu.intel.com/i915: "1"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      ml-model-pull-clip: &ml-model-pull
        type: cronjob
        cronjob:
          schedule: "@yearly"
          concurrencyPolicy: "Replace"
        pod:
          labels:
            egress.home.arpa/internet: allow
        containers:
          app: &ml-model-pull-ct
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v2.4.1@sha256:b3deefd1826f113824e9d7bc30d905e7f823535887d03f869330946b6db3b44a
            command: ["huggingface-cli", "download", "--exclude", ".git", "--local-dir"] # Immich ML image installs huggingface-cli
            args: ["/cache/clip/ViT-B-32__openai", "immich-app/ViT-B-32__openai"]
            workingDir: &mlhome "/cache"
            env:
              HOME: *mlhome
              HF_HOME: *mlhome
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
              limits:
                cpu: "1"
                memory: "2Gi"
      ml-model-pull-facial:
        <<: *ml-model-pull
        containers:
          app:
            <<: *ml-model-pull-ct
            args: ["/cache/facial-recognition/buffalo_l", "immich-app/buffalo_l"]
      redis:
        type: deployment
        replicas: 1
        containers:
          app:
            image:
              repository: "public.ecr.aws/docker/library/redis"
              tag: "8.4.0@sha256:73dad4271642c5966db88db7a7585fae7cf10b685d1e48006f31e0294c29fdd7"
            command: ["redis-server", "--save", "''", "--appendonly", "no"] # save and appendonly options forcibly disable RDB and AOF persistence entirely
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: "32Mi"
              limits:
                cpu: "1"
                memory: "128Mi"
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
    service:
      app:
        controller: app
        primary: true
        ports:
          http:
            port: 80
            targetPort: *http
            protocol: HTTP
            appProtocol: http
            primary: true
          metrics:
            port: *metrics-api
      microservices:
        controller: microservices
        ports:
          metrics:
            port: *metrics-ms
      ml:
        controller: ml
        ports:
          http:
            port: 80
            targetPort: *ml-port
            protocol: HTTP
            appProtocol: http
      redis:
        controller: redis
        ports:
          http:
            port: 6379
    route:
      app:
        hostnames: ["${APP_DNS_IMMICH:=immich}"]
        parentRefs:
          - name: envoy-internal
            namespace: ingress
            sectionName: internal
    persistence:
      data:
        existingClaim: immich-data
        advancedMounts:
          app: &mount
            app:
              - subPath: data
                path: *pvc
          microservices: *mount
          redis:
            redis:
              - subPath: redis
                path: /data
      misc:
        existingClaim: immich-misc
        advancedMounts:
          app: &misc
            app:
              - subPath: encodedvideo
                path: /data/encoded-video
              - subPath: thumbs
                path: /data/thumbs
          microservices: *misc
          ml: &mlpvc # buffalo needs to write to model file to add batch axis
            app:
              - subPath: ml-models-cache
                path: /cache
              - subPath: matplotlib-config
                path: /.config/matplotlib
              - subPath: matplotlib-cache
                path: /.cache/matplotlib
          ml-model-pull-facial: *mlpvc
          ml-model-pull-clip: *mlpvc
      tmp:
        type: emptyDir
        medium: Memory
        sizeLimit: 16Mi
        globalMounts:
          - subPath: tmp
            path: /tmp
          - subPath: geocode
            path: /usr/src/app/.reverse-geocoding-dump
          - subPath: geoname
            path: /usr/src/app/node_modules/local-reverse-geocoder/geonames_dump
          - subPath: transformers
            path: /usr/src/app/.transformers_cache
      pg-ca:
        type: secret
        name: pg-home-ca
        defaultMode: 0400
        globalMounts:
          - subPath: ca.crt
            path: /secrets/pg/ca.crt
    defaultPodOptionsStrategy: merge
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      hostAliases:
        - ip: "${APP_IP_AUTHENTIK:=127.0.0.1}"
          hostnames: ["${APP_DNS_AUTHENTIK:=authentik}"]
      # dnsConfig:
      #   options:
      #     - name: ndots
      #       value: "1"
      runtimeClassName: kata
      securityContext:
        runAsNonRoot: true
        runAsUser: &uid ${APP_UID_IMMICH:=1000}
        runAsGroup: *uid
        fsGroup: *uid
        fsGroupChangePolicy: Always
        seccompProfile: { type: "RuntimeDefault" }
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "fuckoff.home.arpa/{{ .Release.Name }}"
                    operator: DoesNotExist
    networkpolicies:
      immich:
        podSelector: &sel
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values: [immich]
            - key: app.kubernetes.io/instance
              operator: NotIn
              values: [ml-model-pull]
        policyTypes: [Ingress, Egress]
        rules:
          ingress:
            - from: [{podSelector: *sel}]
          egress:
            - to: [{podSelector: *sel}]
    serviceMonitor:
      immich:
        service:
          identifier: app
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
      microservices:
        service:
          identifier: microservices
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
