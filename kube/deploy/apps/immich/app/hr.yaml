---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/common-3.4.0/charts/other/app-template/schemas/helmrelease-helm-v2beta2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: &app immich
  namespace: *app
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 3.4.0
      sourceRef:
        name: bjw-s
        kind: HelmRepository
        namespace: flux-system
  values:
    controllers:
      immich:
        type: deployment
        replicas: 1
        pod:
          labels:
            ingress.home.arpa/nginx-internal: allow
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
            authentik.home.arpa/https: allow
        containers:
          main:
            image: &img
              repository: ghcr.io/immich-app/immich-server
              tag: v1.118.2@sha256:f158810c90f80162f9b08729bbaec963731f12662960be38ff93093b78a0bbdf
            command: &cmd ["tini", "--", "node", "/usr/src/app/dist/main"]
            args: ["immich"]
            env: &env
              TZ: "${CONFIG_TZ}"
              LD_PRELOAD: /usr/lib/x86_64-linux-gnu/libmimalloc.so.2
              NODE_ENV: production
              LOG_LEVEL: verbose
              IMMICH_MEDIA_LOCATION: &pvc /data
              IMMICH_METRICS: "true"
              IMMICH_SERVER_URL: http://immich.immich.svc.cluster.local:3001
              IMMICH_MACHINE_LEARNING_URL: http://immich-ml.immich.svc.cluster.local:3003
              REDIS_HOSTNAME: immich-redis.immich.svc.cluster.local
              REDIS_PORT: "6379"
              DB_VECTOR_EXTENSION: pgvector # I couldn't really care less for worser machine learning, over half my library is screenshots
              DB_URL:
                valueFrom:
                  secretKeyRef:
                    name: pg-home-pguser-immich-fixed
                    key: pgbouncer-uri-sslmode
            envFrom: &ef
              - secretRef:
                  name: immich-secrets
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: ["ALL"]
            resources:
              requests:
                cpu: "10m"
                memory: "128Mi"
              limits:
                cpu: "3000m"
                memory: "2Gi"
      microservices:
        type: deployment
        replicas: 3
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
            prom.home.arpa/kps: allow
          securityContext:
            runAsNonRoot: true
            runAsUser: &uid ${APP_UID_IMMICH:=1000}
            runAsGroup: *uid
            fsGroup: *uid
            fsGroupChangePolicy: Always
            supplementalGroups: [44, 104, 109, 128, 226] # GPU
            seccompProfile: { type: "RuntimeDefault" }
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/instance: *app
                  app.kubernetes.io/component: microservices
        containers:
          main:
            image: *img
            command: *cmd
            args: ["microservices"]
            env: *env
            securityContext: *sc
            resources:
              requests:
                cpu: "100m"
                memory: "300Mi"
                gpu.intel.com/i915: "1"
              limits:
                cpu: "1000m" # my machine will actually die
                memory: "2Gi"
                gpu.intel.com/i915: "1"
      ml:
        type: deployment
        replicas: 3
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-home
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/instance: *app
                  app.kubernetes.io/component: ml
        containers:
          main:
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v1.118.2@sha256:4d89a309fd08a93649f1ae4a7572ae98f09d66b4c1dfb7916b71d31dec7eda38
            env: *env
            securityContext: *sc
            resources:
              requests:
                cpu: "10m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "6Gi"
      ml-model-pull-clip: &ml-model-pull
        type: cronjob
        cronjob:
          schedule: "@daily"
          concurrencyPolicy: "Replace"
        pod:
          labels:
            egress.home.arpa/internet: allow
        containers:
          main: &ml-model-pull-ct
            image:
              repository: ghcr.io/immich-app/immich-machine-learning
              tag: v1.118.2@sha256:4d89a309fd08a93649f1ae4a7572ae98f09d66b4c1dfb7916b71d31dec7eda38
            command: ["huggingface-cli", "download", "--resume-download", "--exclude", ".git", "--cache-dir", "/ml-model-pull-tmp", "--local-dir-use-symlinks", "False", "--local-dir"] # Immich ML image installs huggingface-cli
            args: ["/cache/clip/ViT-B-32__openai", "immich-app/ViT-B-32__openai"]
            securityContext: *sc
            resources:
              requests:
                cpu: "10m"
              limits:
                cpu: "1000m"
                memory: "1Gi"
      ml-model-pull-facial:
        <<: *ml-model-pull
        containers:
          main:
            <<: *ml-model-pull-ct
            args: ["/cache/facial-recognition/buffalo_l", "immich-app/buffalo_l"]
      redis:
        type: deployment
        replicas: 1
        containers:
          redis:
            image:
              repository: "public.ecr.aws/docker/library/redis"
              tag: "7.4.1@sha256:a06cea905344470eb49c972f3d030e22f28f632c1b4f43bbe4a26a4329dd6be5"
            command: ["redis-server", "--save", "300 1", "--appendonly", "yes"] # save and appendonly options forcibly disable RDB and AOF persistence entirely
            securityContext: *sc
            resources:
              requests:
                cpu: "10m"
                memory: "32Mi"
              limits:
                cpu: "1000m"
                memory: "512Mi"
    service:
      immich:
        controller: immich
        ports:
          http:
            port: 2283
          metrics:
            port: 8081
      microservices:
        controller: microservices
        ports:
          metrics:
            port: 8081
      ml:
        controller: ml
        ports:
          http:
            port: 3003
      redis:
        controller: redis
        ports:
          http:
            port: 6379
    ingress:
      main:
        className: nginx-internal
        hosts:
          - host: &host "${APP_DNS_IMMICH:=immich}"
            paths: &paths
              - path: /
                pathType: Prefix
                service:
                  identifier: immich
                  port: http
        tls:
          - hosts: [*host]
    persistence:
      data:
        existingClaim: immich-data
        advancedMounts:
          immich: &mount
            main:
              - subPath: data
                path: *pvc
          microservices: *mount
          redis:
            main:
              - subPath: redis
                path: /data
      misc:
        existingClaim: immich-misc
        advancedMounts:
          immich: &misc
            main:
              - subPath: encodedvideo
                path: /data/encoded-video
              - subPath: thumbs
                path: /data/thumbs
          microservices: *misc
          ml-model-pull-clip:
            main:
              - &mlpvc
                subPath: ml-models-cache
                path: /cache
                readOnly: false
          ml-model-pull-facial:
            main:
              - <<: *mlpvc
          ml:
            main:
              - <<: *mlpvc
                readOnly: true
      tmp-ml-pull:
        type: emptyDir
        globalMounts:
          - subPath: tmp
            path: /ml-model-pull-tmp
      tmp:
        type: emptyDir
        medium: Memory
        sizeLimit: 16Mi
        globalMounts:
          - subPath: tmp
            path: /tmp
          - subPath: geocode
            path: /usr/src/app/.reverse-geocoding-dump
          - subPath: geoname
            path: /usr/src/app/node_modules/local-reverse-geocoder/geonames_dump
          - subPath: transformers
            path: /usr/src/app/.transformers_cache
      pg-ca:
        type: secret
        name: pg-home-ca
        defaultMode: 0400
        globalMounts:
          - subPath: ca.crt
            path: /secrets/pg/ca.crt
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      hostAliases:
        - ip: "${APP_IP_AUTHENTIK:=127.0.0.1}"
          hostnames: ["${APP_DNS_AUTHENTIK:=authentik}"]
      securityContext:
        runAsNonRoot: true
        runAsUser: &uid ${APP_UID_IMMICH:=1000}
        runAsGroup: *uid
        fsGroup: *uid
        fsGroupChangePolicy: Always
        seccompProfile: { type: "RuntimeDefault" }
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: fuckoff.home.arpa/immich
                    operator: DoesNotExist
    networkpolicies:
      immich:
        podSelector: &sel
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values: [immich]
            - key: app.kubernetes.io/instance
              operator: NotIn
              values: [ml-model-pull]
        policyTypes: [Ingress, Egress]
        rules:
          ingress:
            - from: [{podSelector: *sel}]
          egress:
            - to: [{podSelector: *sel}]
    serviceMonitor:
      immich:
        serviceName: immich
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
      microservices:
        serviceName: microservices
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
