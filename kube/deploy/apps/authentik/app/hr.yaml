---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/app-template-4.6.2/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app authentik
  namespace: *app
spec:
  interval: 5m
  chartRef:
    kind: OCIRepository
    name: app-template
    namespace: *app
  values:
    controllers:
      app:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            ingress.home.arpa/nginx-external: allow
            ingress.home.arpa/nginx-internal: allow
            ingress.home.arpa/nginx-public: allow
            egress.home.arpa/nginx-external: allow
            egress.home.arpa/nginx-internal: allow
            egress.home.arpa/nginx-public: allow
            ingress.home.arpa/envoy-external: allow
            ingress.home.arpa/envoy-internal: allow
            egress.home.arpa/envoy-external: allow
            egress.home.arpa/envoy-internal: allow
            db.home.arpa/pg: pg-authentik
            s3.home.arpa/store: "rgw-${CLUSTER_NAME}"
            prom.home.arpa/kps: allow
            # for OIDC sources
            egress.home.arpa/discord: allow
            egress.home.arpa/github: allow
            # files
            egress.home.arpa/r2: allow
          resources:
            requests:
              cpu: 30m
            limits:
              cpu: "1"
              memory: 1Gi
        containers:
          app:
            image: &img
              repository: ghcr.io/goauthentik/dev-server
              tag: gh-version-2025.12@sha256:822594213a80ef0a334a1ba13489579fc1114092390b1e19f9d2b778b70d1604
            args: [server]
            env: &env
              TZ: "${CONFIG_TZ}"
              # PostgreSQL
              AUTHENTIK_POSTGRESQL__HOST: &pghost "pg-authentik-ha.authentik.svc.cluster.local"
                # valueFrom:
                #   secretKeyRef:
                #     name: pg-authentik-pguser-authentik
                #     # key: pgbouncer-host
                #     key: host
              AUTHENTIK_POSTGRESQL__PORT: &pgport
                valueFrom:
                  secretKeyRef:
                    name: pg-authentik-pguser-authentik
                    #key: pgbouncer-port
                    key: port
              AUTHENTIK_POSTGRESQL__NAME: &pgname
                valueFrom:
                  secretKeyRef:
                    name: pg-authentik-pguser-authentik
                    key: dbname
              AUTHENTIK_POSTGRESQL__USER: &pguser
                valueFrom:
                  secretKeyRef:
                    name: pg-authentik-pguser-authentik
                    key: user
              AUTHENTIK_POSTGRESQL__PASSWORD: &pgpass
                valueFrom:
                  secretKeyRef:
                    name: pg-authentik-pguser-authentik
                    key: password
              AUTHENTIK_POSTGRESQL__SSLMODE: &pgssl require # used to be verify-ca because I thought verify-full was mTLS... and now it's causing tls.Config needs serverName or insecureSkipVerify log errors
              AUTHENTIK_POSTGRESQL__SSLROOTCERT: &pgca /secrets/pg/ca.crt
              # pgBouncer / Database Connection Health
              AUTHENTIK_POSTGRESQL__CONN_MAX_AGE: &pgage "600" # if not using pgBouncer, maybe setting this to null for unlimited persistent connections is a good idea: connection slots limit can be reached with authentik
              AUTHENTIK_POSTGRESQL__CONN_HEALTH_CHECKS: &pgcheck "true"
              # AUTHENTIK_POSTGRESQL__DISABLE_SERVER_SIDE_CURSORS: "true"
              # Read Replicas
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__HOST: *pghost
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__PORT: *pgport
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__NAME: *pgname
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__USER: *pguser
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__PASSWORD: *pgpass
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__SSLMODE: *pgssl
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__SSLROOTCERT: *pgca
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__CONN_MAX_AGE: *pgage
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__0__CONN_HEALTH_CHECKS: *pgcheck
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__HOST: "pg-authentik-replicas.authentik.svc.cluster.local"
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__PORT: *pgport
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__NAME: *pgname
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__USER: *pguser
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__PASSWORD: *pgpass
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__SSLMODE: *pgssl
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__SSLROOTCERT: *pgca
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__CONN_MAX_AGE: *pgage
              AUTHENTIK_POSTGRESQL__READ_REPLICAS__1__CONN_HEALTH_CHECKS: *pgcheck
              # media storage
              AUTHENTIK_STORAGE__MEDIA__BACKEND: "s3"
              AUTHENTIK_STORAGE__MEDIA__S3__USE_SSL: "true"
              AUTHENTIK_STORAGE__MEDIA__S3__SECURE_URLS: "true"
              AUTHENTIK_STORAGE__MEDIA__S3__ADDRESSING_STYLE: path
              # misc
              AUTHENTIK_LISTEN__TRUSTED_PROXY_CIDRS: "${IP_POD_CIDR_V4:=127.0.0.1/32}"
              AUTHENTIK_OUTPOSTS__DISCOVER: "false"
              # error reporting
              AUTHENTIK_ERROR_REPORTING__ENABLED: "false"
              AUTHENTIK_ERROR_REPORTING__SEND_PII: "false"
              # disable update checking
              AUTHENTIK_DISABLE_UPDATE_CHECK: "true"
            envFrom: &envFrom
              - secretRef:
                  name: authentik-secrets
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: ["ALL"]
            ports:
              - name: http
                containerPort: &http 9000
              - name: https
                containerPort: &https 9443
              - name: metrics
                containerPort: &metrics 9300
            probes:
              liveness: &probe
                enabled: true
                type: HTTP
                port: http
                path: "/-/health/live/"
                spec:
                  timeoutSeconds: 5
              readiness:
                <<: *probe
                path: "/-/health/ready/"
              startup:
                <<: *probe
                enabled: true
                spec: &startup
                  periodSeconds: 1
                  failureThreshold: 300
                  initialDelaySeconds: 15
          anubis:
            image:
              repository: ghcr.io/xe/x/anubis
              tag: latest@sha256:a7b24490df79512a18a198dc44cd3d8a4ac3389ec91866ec9720d6293c2bdde7
            env:
              TZ: "${CONFIG_TZ}"
              BIND: ":8923"
              DIFFICULTY: "5"
              SERVE_ROBOTS_TXT: "true"
              TARGET: "http://127.0.0.1:9000"
            securityContext: *sc
            ports:
              - name: anubis
                containerPort: &anubis 8923
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      worker:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            db.home.arpa/pg: pg-authentik
            s3.home.arpa/store: "rgw-${CLUSTER_NAME}"
            authentik.home.arpa/https: allow
            prom.home.arpa/kps: allow
            egress.home.arpa/discord: allow
            egress.home.arpa/ad: allow
            # egress.home.arpa/internet: allow
        containers:
          app:
            image: *img
            args: [worker]
            env:
              <<: *env
              AUTHENTIK_WORKER__PROCESSES: "1"
              AUTHENTIK_WORKER__THREADS:
                resourceFieldRef:
                  resource: limits.cpu
            envFrom: *envFrom
            securityContext: *sc
            resources:
              requests:
                cpu: 20m
                # memory: 750Mi
              limits:
                cpu: "1"
                memory: 1Gi # TODO: workers have been memory leaking since 2025.10 due to outpost update tasks flooding Postgres and being scheduled more than 1 per second despite crontab of 28 */4 * * *
            probes:
              readiness: &worker-probe
                enabled: true
                custom: true
                spec: &wps
                  timeoutSeconds: 5
                  exec:
                    command:
                      - /bin/sh
                      - -c
                      - |
                        ak healthcheck &&
                        if curl -s localhost:9300/metrics | grep django_db_errors_total;
                        then false;
                        fi
              liveness:
                <<: *worker-probe
                spec:
                  <<: *wps
                  failureThreshold: 15
              startup:
                <<: *worker-probe
                spec:
                  <<: [*startup, *wps]
      ldap:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            authentik.home.arpa/https: allow
        containers:
          app:
            image:
              <<: *img
              repository: ghcr.io/goauthentik/ldap
              tag: 2025.12.3@sha256:cd74cd7433c6e67c6d3f69f3d339fbfbd5499865b0741d7563a3c3f703927384
            env:
              AUTHENTIK_HOST: "https://${APP_DNS_AUTHENTIK}"
              AUTHENTIK_TOKEN:
                valueFrom:
                  secretKeyRef:
                    name: authentik-tokens
                    key: AUTHENTIK_TOKEN_LDAP
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
              limits:
                cpu: "1"
                memory: 50Mi
            probes:
              liveness: &ldap-probe
                enabled: true
                custom: true
                spec: &lps
                  exec:
                    command: ["/ldap", "healthcheck"]
              readiness: *ldap-probe
              startup:
                <<: *ldap-probe
                spec:
                  <<: [*startup, *lps]
      radius:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            authentik.home.arpa/https: allow
        containers:
          app:
            image:
              <<: *img
              repository: ghcr.io/goauthentik/radius
              tag: 2025.12.3@sha256:e4ed4c6e18e715ada502c0b8cc481b555931aaec84b2794254cb23d2461ae1da
            env:
              AUTHENTIK_HOST: "https://${APP_DNS_AUTHENTIK}"
              AUTHENTIK_TOKEN:
                valueFrom:
                  secretKeyRef:
                    name: authentik-tokens
                    key: AUTHENTIK_TOKEN_RADIUS
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
              limits:
                cpu: "1"
                memory: "50Mi"
            probes:
              liveness: &radius-probe
                enabled: true
                custom: true
                spec: &rps
                  exec:
                    command: ["/radius", "healthcheck"]
              readiness: *radius-probe
              startup:
                <<: *radius-probe
                spec:
                  <<: [*startup, *rps]
      rac:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          labels:
            authentik.home.arpa/https: allow
            egress.home.arpa/ad: allow
            egress.home.arpa/lan: allow
        containers:
          app:
            image:
              <<: *img
              repository: ghcr.io/goauthentik/rac
              tag: 2025.12.3@sha256:d3a9bcb1f203699e20508762fc06810a843f389e38170de4b216b8bd59f9f55b
            env:
              AUTHENTIK_HOST: "https://${APP_DNS_AUTHENTIK}"
              AUTHENTIK_TOKEN:
                valueFrom:
                  secretKeyRef:
                    name: authentik-tokens
                    key: AUTHENTIK_TOKEN_RAC
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
              limits:
                cpu: "1"
                memory: "50Mi"
            probes:
              liveness: &rac-probe
                enabled: true
                custom: true
                spec: &rps
                  exec:
                    command: ["/rac", "healthcheck"]
              readiness: *rac-probe
              startup:
                <<: *rac-probe
                spec:
                  <<: [*startup, *rps]
    service:
      app:
        controller: app
        forceRename: *app
        ports:
          http: &port
            port: *http
            protocol: HTTP
            appProtocol: http
          http-80:
            <<: *port
            port: 80
            targetPort: *http
          metrics:
            <<: *port
            port: *metrics
          anubis:
            <<: *port
            port: *anubis
      expose:
        primary: false
        controller: app
        type: LoadBalancer
        sessionAffinity: ClientIP
        annotations:
          io.cilium/internal: "true"
          io.cilium/lb-ipam-ips: "${APP_IP_AUTHENTIK:=127.0.0.1}"
        ports:
          https:
            port: 443
            targetPort: *https
            protocol: HTTPS
            appProtocol: https
      ldap:
        primary: false
        controller: ldap
        type: LoadBalancer
        annotations:
          coredns.io/hostname: "${APP_DNS_AUTHENTIK_LDAP:=authentik-ldap}"
          io.cilium/lb-ipam-ips: "${APP_IP_AUTHENTIK_LDAP:=127.0.0.1}"
        ports:
          ldap-tcp: &ldap
            port: 389
            targetPort: 3389
            protocol: TCP
            appProtocol: ldap
          ldap-udp:
            <<: *ldap
            protocol: UDP
          ldaps-tcp: &ldaps
            port: 636
            targetPort: &ldapsPort 6636
            protocol: TCP
            appProtocol: ldaps
          ldaps-udp:
            <<: *ldaps
            protocol: UDP
      radius:
        primary: false
        controller: radius
        type: LoadBalancer
        annotations:
          coredns.io/hostname: "${APP_DNS_AUTHENTIK_RADIUS:=authentik-radius}"
          io.cilium/lb-ipam-ips: "${APP_IP_AUTHENTIK_RADIUS:=127.0.0.1}"
        ports:
          radius-tcp: &radius
            port: 1812
            protocol: TCP
            appProtocol: radius
          radius-udp:
            <<: *radius
            protocol: UDP
    route:
      app:
        hostnames: &host ["${APP_DNS_AUTHENTIK:=authentik}"]
        parentRefs:
          - name: envoy-internal
            namespace: ingress
            sectionName: internal
        rules:
          - backendRefs:
              - identifier: app
                port: *http
      external:
        annotations:
          external-dns.alpha.kubernetes.io/target: "${DNS_CF:=cf}"
          external-dns.alpha.kubernetes.io/cloudflare-proxied: "true"
        hostnames: *host
        parentRefs:
          - name: envoy-external
            namespace: ingress
            sectionName: external
        rules:
          - backendRefs:
              - identifier: app
                port: *anubis
      harden:
        hostnames: *host
        parentRefs:
          - name: envoy-external
            namespace: ingress
            sectionName: external
        rules:
          - matches:
              - path:
                  type: PathPrefix
                  value: /if/admin
              - path:
                  type: PathPrefix
                  value: /api/v3/policies/expression
              - path:
                  type: PathPrefix
                  value: /api/v3/propertymappings
              - path:
                  type: PathPrefix
                  value: /api/v3/managed/blueprints
            filters:
              - type: RequestRedirect
                requestRedirect:
                  statusCode: 301
                  hostname: www.google.com
                  port: 443
                  path:
                    type: ReplaceFullPath
                    replaceFullPath: "/"
      forward-auth:
        parentRefs:
          - name: envoy-internal
            namespace: ingress
            sectionName: internal
          - name: envoy-external
            namespace: ingress
            sectionName: external
        rules:
          - matches:
              - path:
                  type: PathPrefix
                  value: /outpost.goauthentik.io
            backendRefs:
              - identifier: app
                port: *http
    persistence:
      pg-ca:
        type: secret
        #name: pg-authentik-pgbouncer
        name: pg-authentik-cluster-cert
        defaultMode: 0400
        globalMounts:
          - subPath: ca.crt
            #subPath: pgbouncer-frontend.ca-roots
            path: *pgca
      tls:
        type: secret
        name: authentik-tls
        defaultMode: 0400
        globalMounts:
          - path: "/certs/${APP_DNS_AUTHENTIK}-k8s"
      tmp:
        type: emptyDir
        medium: Memory
        globalMounts:
          - subPath: media
            path: "/media/public"
        advancedMounts:
          rac:
            app:
              - subPath: freerdp
                path: /home/guacd/.config/freerdp
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      runtimeClassName: kata
      # hostUsers: false
      hostAliases:
        - ip: "${APP_IP_AUTHENTIK:=127.0.0.1}"
          hostnames: ["${APP_DNS_AUTHENTIK:=authentik}"]
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      securityContext:
        runAsNonRoot: true
        runAsUser: &uid 1000
        runAsGroup: *uid
        fsGroup: *uid
        fsGroupChangePolicy: Always
        seccompProfile: { type: "RuntimeDefault" }
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "fuckoff.home.arpa/{{ .Release.Name }}"
                    operator: DoesNotExist
    networkpolicies:
      same-ns:
        podSelector: {}
        policyTypes: [Ingress, Egress]
        rules:
          ingress: [from: [{podSelector: {}}]]
          egress: [to: [{podSelector: {}}]]
    serviceMonitor:
      authentik:
        service:
          identifier: app
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
