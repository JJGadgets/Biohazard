---
apiVersion: cilium.io/v2alpha1
kind: CiliumBGPPeeringPolicy
# MAKE SURE CRDs ARE INSTALLED IN CLUSTER VIA cilium-config ConfigMap OR Cilium HelmRelease/values.yaml (bgpControlPlane.enabled: true), BEFORE THIS IS APPLIED!
# "CiliumBGPPeeringPolicy" Custom Resource will replace the old MetalLB BGP's "bgp-config" ConfigMap
# "CiliumBGPPeeringPolicy" is used with `bgpControlPlane.enabled: true` which uses GoBGP, NOT the old `bgp.enabled: true` which uses MetalLB
metadata:
  name: bgp-loadbalancer-ip-main
spec:
  nodeSelector:
    matchLabels:
      kubernetes.io/os: "linux" # match all Linux nodes, change this to match more granularly if more than 1 PeeringPolicy is to be used throughout cluster
  virtualRouters:
    - localASN: ${ASN_ROUTER} # ASNs are processed in uint32
      exportPodCIDR: false
      serviceSelector: # this replaces address-pools, instead of defining the range of IPs that can be assigned to LoadBalancer services, now services have to match below selectors for their LB IPs to be announced
        matchExpressions:
          - {key: thisFakeSelector, operator: NotIn, values: ['will-match-and-announce-all-services']}
      neighbors:
        - peerAddress: "${IP_ROUTER_VLAN_K8S}/32" # unlike bgp-config ConfigMap, peerAddress needs to be in CIDR notation
          peerASN: ${ASN_ROUTER}
    - localASN: ${ASN_EC2_INGRESS}
      exportPodCIDR: false
      serviceSelector:
        matchExpressions:
          - {key: thisFakeSelector, operator: NotIn, values: ['will-match-and-announce-all-services']}
      neighbors:
        - peerAddress: "${IP_EC2_NON_K8S}/32"
          peerASN: ${ASN_EC2_INGRESS}
---
apiVersion: "cilium.io/v2alpha1"
kind: CiliumLoadBalancerIPPool
metadata:
  name: main-pool
spec:
  cidrs:
    - cidr: "${IP_LB_CIDR}"
---
apiVersion: "cilium.io/v2alpha1"
kind: CiliumLoadBalancerIPPool
metadata:
  name: dns
spec:
  cidrs:
    - cidr: "${IP_LB_DNS_CIDR}"
  serviceSelector:
    matchLabels:
      exposeSvc: dns
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: bgp-config # this "bgp-config" ConfigMap is used for the old `bgp.enabled: true` which is the old MetalLB BGP, this will be deprecated in future releases
  namespace: kube-system
data:
  config.yaml: |
    peers:
      - peer-address: "${IP_ROUTER_VLAN_K8S}"
        peer-asn: ${ASN_ROUTER}
        my-asn: ${ASN_ROUTER}
      - peer-address: "${IP_EC2_NON_K8S}"
        peer-asn: ${ASN_EC2_INGRESS}
        my-asn: ${ASN_EC2_INGRESS}
    address-pools:
      - name: main-addr-pool
        protocol: bgp
        avoid-buggy-ips: true
        addresses:
          - "${IP_LB_CIDR}"
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: cilium
  namespace: kube-system
  annotations:
    meta.helm.sh/release-name: cilium
    meta.helm.sh/release-namespace: kube-system
  labels:
    app.kubernetes.io/managed-by: Helm
spec:
  interval: 5m
  chart:
    spec:
      chart: cilium
      version: 1.13.0
      sourceRef:
        kind: HelmRepository
        name: cilium-charts
        namespace: flux-system
      interval: 5m
  install:
    # perform remediation when helm install fails
    remediation:
      retries: 100
  upgrade:
    # perform remediation when helm upgrade fails
    remediation:
      retries: 100
      # remediate the last failure, when no retries remain
      remediateLastFailure: true
    cleanupOnFail: true
  values:
    securityContext: # required for Talos
      privileged: true
      capabilities:
        ciliumAgent: "{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}"
        cleanCiliumState: "{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}"
    cgroup:
      autoMount:
        enabled: false
      hostRoot: "/sys/fs/cgroup"

    cluster:
      name: "${CLUSTER_NAME}"
      id: 1
    tunnel: vxlan
    autoDirectNodeRoutes: false
    # ipv4NativeRoutingCIDR: "${IP_POD_CIDR_V4}"
    localRedirectPolicy: true
    ipam:
      mode: kubernetes
      # mode: cluster-pool-v2beta
      # operator:
      #   clusterPoolIPv4PodCIDRList:
      #     - "${IP_POD_CIDR_V4}"
      #   clusterPoolIPv4MaskSize: 24
    # bgp:
    #   enabled: true
    #   announce:
    #     loadbalancerIP: true
    #     podCIDR: true
    bgpControlPlane:
      enabled: true
        # `bgp.announce` block is moved to CiliumBGPPeeringPolicy used by bgpControlPlane, for more fine grained control over announced addresses
        # bgpControlPlane is newer GoBGP implementation, `bgp.enabled: true` and `bgp.announce` uses older MetalLB BGP implementation that is planned to be deprecated in Cilium v1.15.
    loadBalancer:
      algorithm: maglev
      mode: snat
      # mode: dsr
    nodePort:
      enabled: true
      range: 80,32767
    bandwidthManager:
      enabled: false
    l7Proxy: true
    kubeProxyReplacement: strict
    k8sServiceHost: ${IP_CLUSTER_VIP}
    k8sServicePort: 6443
    kubeProxyReplacementHealthzBindAddr: 0.0.0.0:10256
    hubble:
      enabled: true
      peerService:
        clusterDomain: cluster.local
      relay:
        enabled: true
      ui:
        enabled: true
        rollOutPods: true
        ingress:
          enabled: true
          className: "nginx"
          hosts:
            - "${APP_DNS_HUBBLE}"
          tls:
            - hosts:
                - "${APP_DNS_HUBBLE}"
      tls:
        enabled: true
        auto:
          enabled: true
          method: "helm"
          certValidityDuration: 3650
    rollOutCiliumPods: true
    operator:
      rollOutPods: true
